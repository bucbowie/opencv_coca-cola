import urllib
import cv2
import numpy as np
import os
'''001-if-000-fails_url_pull.py
pulls images off the intenet and saves
them locally, as-is. The images are taken
from image-net.org and uses the url_id 
to hold the image-net url suffix pointing 
to the list of images we wish to download.'''

#--------------------------------#
def check_directories(in_dir):
#--------------------------------#
    if not os.path.exists(in_dir):
        print("Error: 001-if-000-fails_url_pull.py \n--------------------------------#\nThe needed input directory: {0}\ndoes not exist and impedes running this program.\nEnsure directory {0} exists, is readable,\n".format(in_dir))
        raise FileNotFoundError

#--------------------------------#
def ensure_directories(my_dir):
#--------------------------------#
    if not os.path.exists(my_dir):
        os.makedirs(my_dir)

#--------------------------------#
def scrap_raw(url_id):
#--------------------------------#
    image_list_urls = urllib.urlopen('http://image-net.org/api/text/imagenet.synset.geturls?wnid=' + url_id).read().decode()
    pic_num  = 1

    for i in image_list_urls.split('\n'):
        try:
            print("INFO: Processing: " + i)
            urllib.urlretrieve(i,  scrape_dir + "/" +   str(pic_num) + ".jpg")
            if os.path.getsize(scrape_dir + "/" + str(pic_num) + ".jpg") > size_smallest_img:
                pic_num += 1
        except Exception as e:
            print(str(e))

#################################################
# M A I N   L O G I C
#################################################
size_smallest_img = (1024 * 5) #Minimum image size we will accept as valid image.
url_id = "n00007846"  #The image-net.org url suffix of desired images url generated by image-net.org
scrape_dir =  '/mnt/usb/raw_neg' #The place to store the freshly scraped images
ensure_directories(scrape_dir)   #Build directories if they do not exist
scrap_raw(url_id)     #Pull images from internet (image-net.org)
